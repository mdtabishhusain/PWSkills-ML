{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb1d3f54-275d-44e8-b5cb-09428fb34ca3",
   "metadata": {},
   "source": [
    "Q1. What is the purpose of grid search cv in machine learning, and how does it work?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2ab383-8d61-46ca-b659-39cea0056557",
   "metadata": {},
   "source": [
    "i.\tGrid Search CV: In grid search CV we use combination of grid search and cross validation. Grid Search makes combination of multiple parameters and apply the combination through CV on the train and validation data to find the accuracy. The combination with best accuracy is selected to train the model. Grid Search CV helps in increasing the model performance. \n",
    "The disadvantage of Grid Search CV is that it has high time complexity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9254619a-7e29-4ed3-96b1-881e7d126503",
   "metadata": {},
   "source": [
    "Q2. Describe the difference between grid search cv and randomize search cv, and when might you choose\n",
    "one over the other?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7843ffbb-03cc-47ac-be11-5f79bd7c657a",
   "metadata": {},
   "source": [
    "i.\tGrid Search CV: In grid search CV we use combination of grid search and cross validation. Grid Search makes combination of multiple parameters and apply the combination through CV on the train and validation data to find the accuracy. The combination with best accuracy is selected to train the model. Grid Search CV helps in increasing the model performance. \n",
    "The disadvantage of Grid Search CV is that it has high time complexity\n",
    "ii.\tRandomized Search CV: Randomized search CV is similar to grid search CV but in randomized search CV we use a variable n_itr which defines number of iterations. The provided value of n_itr randomly selects combinations of parameters unlike grid search CV where all combinations are taken. This leads to decline in time complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fe7dd5-1b5c-4d1a-ad62-16e0194383eb",
   "metadata": {},
   "source": [
    "Q3. What is data leakage, and why is it a problem in machine learning? Provide an example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08aad5f-ba6c-4dce-8a1c-6a8ec30e4e71",
   "metadata": {},
   "source": [
    "Whenever we create a machine learning model, we divide our dataset into these 3 parts in order to get the best performance. Also the test dataset is kept hidden while training the model as it may affect the accuracy of prediction of the model. If some part of test dataset is shown while model training then the situation is known as data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b16709f-3b3e-4600-8e6a-6c34ec8f7663",
   "metadata": {},
   "source": [
    "Q4. How can you prevent data leakage when building a machine learning model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec2b516-7c09-4d6f-aff3-e5c5ca5a7657",
   "metadata": {},
   "source": [
    "Whenever we create a machine learning model, we divide our dataset into these 3 parts in order to get the best performance. Also the test dataset is kept hidden while training the model as it may affect the accuracy of prediction of the model. If some part of test dataset is shown while model training then the situation is known as data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21109b12-e67a-4be0-b017-935548873fe2",
   "metadata": {},
   "source": [
    "Q5. What is a confusion matrix, and what does it tell you about the performance of a classification model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1945f06a-c1bf-43b1-a295-9b625a05c27a",
   "metadata": {},
   "source": [
    "Confusion Matrix: In binary classification, confusion matrix is a 2 X 2 matrix where columns are the actual values of the model, i.e. y and rows are the predicted values of the model, i.e. y ̂. Confusion matrix is shown in the table.\n",
    "TP and TN are True positive and True negative respectively. True positive is when both actual and predicted values are and true negative is when both the values are 0. So TP and TN are the correct predictions. FP and FN are False positive and False negative respectively. False positive when actual value is 0 and predicted value is 1 and false negative is when actual value is 1 and predicted value is 0. So FP and FN are incorrect predictions\n",
    "\t1\t0\n",
    "1\tTP=3\tFP=2\n",
    "0\tFN=1\tTN=1\n",
    "The accuracy of the model is given by\n",
    "Model Acc=(TP+TN)/(TP+TN+FP+FN)\n",
    "Suppose in a model total True positives are 3 and False positive is 1 and total True negatives are 2 and False negative is 1 then the matrix formed will be: \n",
    "The accuracy of the model is then given by \n",
    "Model acc=(3+1)/(3+2+1+1)=4/7=0.57=57%\n",
    "The disadvantage with confusion matrix is that it cannot be used in an imbalanced dataset scenario. For imbalanced dataset we use precision and recall. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318bd21b-38c1-4141-ad29-6cc4fb3302b2",
   "metadata": {},
   "source": [
    "Q6. Explain the difference between precision and recall in the context of a confusion matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4034a9be-2019-4176-a242-0cab49959e47",
   "metadata": {},
   "source": [
    "Precision: Precision states that out of all the actual values, how many are correctly predicted. Here the false positive is reduced and the importance of false positive is also taken into consideration. Precision is given by:\n",
    "Precision=TP/(TP+FP)\n",
    "\tRecall: Recall states that out of all the predicted values, how many are correctly predicted with actual values. Here false negative is reduced and the importance of false negative is also taken into consideration. Recall is given by:\n",
    "Recall=TP/(TP+FN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2da6cc2-8288-4c23-b813-893c735eaefa",
   "metadata": {},
   "source": [
    "Q7. How can you interpret a confusion matrix to determine which types of errors your model is making?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a256e2bc-541b-4a14-a0a5-221cd22e81e2",
   "metadata": {},
   "source": [
    "Confusion Matrix: In binary classification, confusion matrix is a 2 X 2 matrix where columns are the actual values of the model, i.e. y and rows are the predicted values of the model, i.e. y ̂. Confusion matrix is shown in the table.\n",
    "TP and TN are True positive and True negative respectively. True positive is when both actual and predicted values are and true negative is when both the values are 0. So TP and TN are the correct predictions. FP and FN are False positive and False negative respectively. False positive when actual value is 0 and predicted value is 1 and false negative is when actual value is 1 and predicted value is 0. So FP and FN are incorrect predictions\n",
    "\t1\t0\n",
    "1\tTP=3\tFP=2\n",
    "0\tFN=1\tTN=1\n",
    "The accuracy of the model is given by\n",
    "Model Acc=(TP+TN)/(TP+TN+FP+FN)\n",
    "Suppose in a model total True positives are 3 and False positive is 1 and total True negatives are 2 and False negative is 1 then the matrix formed will be: \n",
    "The accuracy of the model is then given by \n",
    "Model acc=(3+1)/(3+2+1+1)=4/7=0.57=57%\n",
    "The disadvantage with confusion matrix is that it cannot be used in an imbalanced dataset scenario. For imbalanced dataset we use precision and recall. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b128d65-996e-48e2-8716-d4a00d77fb2f",
   "metadata": {},
   "source": [
    "Q8. What are some common metrics that can be derived from a confusion matrix, and how are they\n",
    "calculated?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235e4976-e124-41cd-b4c5-6ee0bcb0b401",
   "metadata": {},
   "source": [
    "Precision: Precision states that out of all the actual values, how many are correctly predicted. Here the false positive is reduced and the importance of false positive is also taken into consideration. Precision is given by:\n",
    "Precision=TP/(TP+FP)\n",
    "\tRecall: Recall states that out of all the predicted values, how many are correctly predicted with actual values. Here false negative is reduced and the importance of false negative is also taken into consideration. Recall is given by:\n",
    "Recall=TP/(TP+FN)\n",
    "\tF – Beta Score: F – Beta Score takes both, precision and recall into consideration as important. It is given by:\n",
    "F-β Score=(1+β^2 )  (Precision × Recall)/(Precision+Recall)\n",
    "There are 3 condition in F Beta Score:\n",
    "\tIf both FP and FN are important then\n",
    "β=1 and F 1 score=2×(Precision × Recall)/(Precision+Recall)\n",
    "This is known as harmonic mean\n",
    "\tIf FP is more important than FN then\n",
    "β=0.5 and F 0.5 score=1.25×(Precision × Recall)/(Precision+Recall)\n",
    "\tIf FN is more important than FN then \n",
    "β=2 and F 2 score=5×(Precision × Recall)/(Precision+Recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8484a1e3-64fa-41e0-8bf0-3f7bf7c8ff61",
   "metadata": {},
   "source": [
    "Q9. What is the relationship between the accuracy of a model and the values in its confusion matrix?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4fc797-7b26-47c8-a5be-d430d8ded085",
   "metadata": {},
   "source": [
    "We have already learned that a dataset is divided into 3 parts train, validation and test. The train and validation data set is used for training the model while test dataset is used for testing the model. First the dataset is divided into train and test. Then the training dataset is divided into train and validation dataset. This separation is done with the help of train_test_split module of sklearn library. While splitting the dataset we give a value called test_size and random_state. The test_size determines the size of test dataset and random_state is used to determine size of validation dataset.\n",
    "But there is a catch. For different values of random_state we get different accuracy for the same training data. For example if random_state is 100 we might get accuracy of 85% or if random_state is 42 accuracy might be 70%. So to overcome this situation cross validation is used. \n",
    "Cross validation takes out the mean of all accuracy obtain by changing the random_state. For example if the random_state is changed thrice and the accuracy in these cases are 80%, 85% and 78% then the final accuracy after cross validation will be, (80+85+78)/3=81%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65379c48-c7a7-44a2-8383-b3d4981456b5",
   "metadata": {},
   "source": [
    "Q10. How can you use a confusion matrix to identify potential biases or limitations in your machine learning\n",
    "model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5993c7-ee7b-4edd-a972-5af5ded16f16",
   "metadata": {},
   "source": [
    "We have already learned that a dataset is divided into 3 parts train, validation and test. The train and validation data set is used for training the model while test dataset is used for testing the model. First the dataset is divided into train and test. Then the training dataset is divided into train and validation dataset. This separation is done with the help of train_test_split module of sklearn library. While splitting the dataset we give a value called test_size and random_state. The test_size determines the size of test dataset and random_state is used to determine size of validation dataset.\n",
    "But there is a catch. For different values of random_state we get different accuracy for the same training data. For example if random_state is 100 we might get accuracy of 85% or if random_state is 42 accuracy might be 70%. So to overcome this situation cross validation is used. \n",
    "Cross validation takes out the mean of all accuracy obtain by changing the random_state. For example if the random_state is changed thrice and the accuracy in these cases are 80%, 85% and 78% then the final accuracy after cross validation will be, (80+85+78)/3=81%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad105611-df56-4639-b6cb-90acd31725cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
