{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b37e69b-946e-47dd-b61e-c35bfa35263b",
   "metadata": {},
   "source": [
    "Q1. What is Random Forest Regressor?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed84c0e-6b0a-4ec4-b572-d1e8b3c65cd4",
   "metadata": {},
   "source": [
    "Random Forest is a successful method based on Bagging and Decision Trees. As we have already studied in bagging the subsets of the dataset are trained using different ML algorithms. But in random forest, only decision tree is used for training the subsets of the dataset. The subsets are formed by using row sampling and feature sampling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d10e00-ba6c-4e22-8699-3e15cfead8e1",
   "metadata": {},
   "source": [
    "Q2. How does Random Forest Regressor reduce the risk of overfitting?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ea5c46-017a-4337-9b70-1cdfae85f1e7",
   "metadata": {},
   "source": [
    "We know decision tree is prone to overfitting which gives a low bias training data and a high variance test data. To overcome this we use parameters like pre pruning and post pruning. But in Random Forest, since there are multiple decision trees, the training data is of low bias but the test data is also of low variance which is an ideal condition. Therefore Random Forest is preferred over Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c401bf1-d716-47a0-8420-912b3ce2f978",
   "metadata": {},
   "source": [
    "Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c9f716-6a00-460d-ab8a-de40668e3a76",
   "metadata": {},
   "source": [
    "We know decision tree is prone to overfitting which gives a low bias training data and a high variance test data. To overcome this we use parameters like pre pruning and post pruning. But in Random Forest, since there are multiple decision trees, the training data is of low bias but the test data is also of low variance which is an ideal condition. Therefore Random Forest is preferred over Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3c78b5-70a9-4f1f-97be-99b9a9c043ba",
   "metadata": {},
   "source": [
    "Q4. What are the hyperparameters of Random Forest Regressor?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec25aeb6-e304-46a8-94fb-18a091736ccb",
   "metadata": {},
   "source": [
    "The Random Forest Regressor is an ensemble machine learning algorithm used for regression tasks. It is an extension of the Random Forest algorithm used for classification. Random Forest Regressor has several hyperparameters that allow you to control the behavior and performance of the model. Some of the most commonly used hyperparameters for the Random Forest Regressor are:\n",
    "\n",
    "n_estimators: This hyperparameter determines the number of decision trees in the forest. Increasing the number of trees generally improves the model's performance, up to a point. However, it also increases computation time. You need to find an appropriate balance for your specific problem.\n",
    "\n",
    "max_features: It controls the maximum number of features each tree is allowed to consider when making a split. You can specify it as a number (e.g., 0.5 for half of the features) or as a string (\"auto,\" \"sqrt,\" \"log2,\" or None). The choice of this hyperparameter affects the diversity of the trees and can impact the model's performance.\n",
    "\n",
    "max_depth: This limits the maximum depth of each decision tree in the forest. It helps prevent overfitting. If not specified, nodes are expanded until they contain less than min_samples_split samples.\n",
    "\n",
    "min_samples_split: It sets the minimum number of samples required to split an internal node. Smaller values make the tree more prone to overfitting, while larger values make it more robust but may underfit.\n",
    "\n",
    "min_samples_leaf: It specifies the minimum number of samples required to be in a leaf node. Like min_samples_split, it controls overfitting and should be tuned accordingly.\n",
    "\n",
    "bootstrap: A Boolean value indicating whether to use bootstrapping when building trees. Bootstrapping involves random sampling with replacement from the training data. Setting it to True is the standard approach.\n",
    "\n",
    "random_state: This is used for reproducibility. You can set a specific seed for random number generation to ensure that your results are consistent across different runs.\n",
    "\n",
    "n_jobs: The number of CPU cores to use for parallel processing during training. Setting it to -1 uses all available cores.\n",
    "\n",
    "oob_score: A Boolean value indicating whether to use out-of-bag (OOB) samples to estimate the R-squared score of the model. OOB samples are data points that were not included in the bootstrapped training sets for each tree.\n",
    "\n",
    "criterion: The function used to measure the quality of a split. For regression, \"mse\" (Mean Squared Error) is typically used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ac2cdc-12b2-4173-b794-11c1cb383244",
   "metadata": {},
   "source": [
    "Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da7779-f0df-46fa-964d-05e6f2fe9a25",
   "metadata": {},
   "source": [
    "The key difference lies in the ensemble nature of the Random Forest Regressor, which combines the predictions of multiple decision trees to improve performance and robustness. Decision trees are simpler and more interpretable but can be limited by their susceptibility to overfitting. The choice between the two models depends on the specific characteristics of your dataset and the balance between interpretability and predictive power that you require for your regression task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0839f82-bacc-46a3-9946-44bf5f24ce36",
   "metadata": {},
   "source": [
    "Q6. What are the advantages and disadvantages of Random Forest Regressor?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa427a6-2435-4b62-b740-6f003556e029",
   "metadata": {},
   "source": [
    "The Random Forest Regressor is a powerful and versatile algorithm with strong predictive capabilities, but it comes with trade-offs in terms of model interpretability, model size, and computational resources. It is well-suited for many regression tasks, but the choice of algorithm should be made with consideration of the specific characteristics of your data and the goals of your project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7febeb87-8982-47f3-b9a8-69fcfef8f9c7",
   "metadata": {},
   "source": [
    "Q7. What is the output of Random Forest Regressor?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93aeee6-148b-4b1a-8113-2c9c337d48f2",
   "metadata": {},
   "source": [
    "The output of a Random Forest Regressor is a continuous numeric value, representing the predicted target or dependent variable for a given input or set of input features. In other words, it provides a prediction of a numerical value rather than a classification into distinct classes, as we would get from a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec67515-8ccd-49cf-90e9-f10726aac4f0",
   "metadata": {},
   "source": [
    "Q8. Can Random Forest Regressor be used for classification tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441ffa32-230b-429a-83f6-3c99e93ecc9c",
   "metadata": {},
   "source": [
    "The Random Forest Regressor is specifically designed for regression tasks, which involve predicting continuous numerical values. It is not intended for classification tasks, where the goal is to predict the category or class to which an input data point belongs.\n",
    "However, the Random Forest algorithm has a counterpart that is designed for classification tasks, known as the \"Random Forest Classifier.\" In a Random Forest Classifier, the ensemble of decision trees is used to classify data points into different categories or classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d0d75c-0d60-44be-be78-e3b2528960a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
