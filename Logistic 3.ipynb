{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e907139b-07b4-46ea-82c9-87d059f9e1e6",
   "metadata": {},
   "source": [
    "Q1. Explain the concept of precision and recall in the context of classification models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afae8c2e-ff0b-4906-900b-b2ec6f8d2f92",
   "metadata": {},
   "source": [
    "Precision: Precision states that out of all the actual values, how many are correctly predicted. Here the false positive is reduced and the importance of false positive is also taken into consideration. Precision is given by:\n",
    "Precision=TP/(TP+FP)\n",
    "\tRecall: Recall states that out of all the predicted values, how many are correctly predicted with actual values. Here false negative is reduced and the importance of false negative is also taken into consideration. Recall is given by:\n",
    "Recall=TP/(TP+FN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1f60f6-3637-42a4-b43c-a12613dd6a3b",
   "metadata": {},
   "source": [
    "Q2. What is the F1 score and how is it calculated? How is it different from precision and recall?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d846ab-b144-4bf8-a171-75a8af0989d9",
   "metadata": {},
   "source": [
    "F – Beta Score: F – Beta Score takes both, precision and recall into consideration as important. It is given by:\n",
    "F-β Score=(1+β^2 )  (Precision × Recall)/(Precision+Recall)\n",
    "There are 3 condition in F Beta Score:\n",
    "\tIf both FP and FN are important then\n",
    "β=1 and F 1 score=2×(Precision × Recall)/(Precision+Recall)\n",
    "This is known as harmonic mean\n",
    "\tIf FP is more important than FN then\n",
    "β=0.5 and F 0.5 score=1.25×(Precision × Recall)/(Precision+Recall)\n",
    "\tIf FN is more important than FN then \n",
    "β=2 and F 2 score=5×(Precision × Recall)/(Precision+Recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8532104b-5494-4834-b656-23db1a6df4c4",
   "metadata": {},
   "source": [
    "Q3. What is ROC and AUC, and how are they used to evaluate the performance of classification models?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dac4775-452b-4dfa-ad57-889afb1d890b",
   "metadata": {},
   "source": [
    "Logistic regression multiclass classification is used when there are more than 2 categorical variables in the output feature. There are 2 methods for finding multiclass classification which are used simultaneously.\n",
    "\tOne Versus Rest (OVR): In one versus rest, based on number of categories two groups are formed one contains a single category and other contains the rest of the categories. To understand better let's consider an example – suppose there are 3 categories in the output feature. Each category is grouped are 3 different groups are formed say O_1  ,O_2  and O_3 when O_1 group is taken into consideration O_2  and O_3 are clubbed together. This make it a binary classification with 2 categories - O_1 and (O_2  ,O_3). Now with help of Logistic Regression the model for this binary classification is trained. This is repeated taking into consideration each group.\n",
    "\tMultinomial: After OVR each group is one hot encoded i.e. the group taken into consideration is marked 1 and rest marked 0. When new data is provided, we get output for each group and the probability of each group is taken and the group with highest probability will be the output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ae05df-10f0-494e-bec2-89b1099545c6",
   "metadata": {},
   "source": [
    "Q4. How do you choose the best metric to evaluate the performance of a classification model?\n",
    "What is multiclass classification and how is it different from binary classification?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a881ff-bb88-4ba7-bf8d-4cff54efa535",
   "metadata": {},
   "source": [
    "Logistic regression multiclass classification is used when there are more than 2 categorical variables in the output feature. There are 2 methods for finding multiclass classification which are used simultaneously.\n",
    "\tOne Versus Rest (OVR): In one versus rest, based on number of categories two groups are formed one contains a single category and other contains the rest of the categories. To understand better let's consider an example – suppose there are 3 categories in the output feature. Each category is grouped are 3 different groups are formed say O_1  ,O_2  and O_3 when O_1 group is taken into consideration O_2  and O_3 are clubbed together. This make it a binary classification with 2 categories - O_1 and (O_2  ,O_3). Now with help of Logistic Regression the model for this binary classification is trained. This is repeated taking into consideration each group.\n",
    "\tMultinomial: After OVR each group is one hot encoded i.e. the group taken into consideration is marked 1 and rest marked 0. When new data is provided, we get output for each group and the probability of each group is taken and the group with highest probability will be the output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b83db9-9205-4e7b-ac44-0ee71eff47ce",
   "metadata": {},
   "source": [
    "Q5. Explain how logistic regression can be used for multiclass classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d592bd1-3c08-4eab-af35-f27c6ae092fc",
   "metadata": {},
   "source": [
    "Logistic regression multiclass classification is used when there are more than 2 categorical variables in the output feature. There are 2 methods for finding multiclass classification which are used simultaneously"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cc125d-8ef9-4b9c-aa36-863ca3bdab1d",
   "metadata": {},
   "source": [
    "Q6. Describe the steps involved in an end-to-end project for multiclass classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8cef92-6d49-415a-971c-585881d86f98",
   "metadata": {},
   "source": [
    "similiar to singular class\n",
    "1. Feature engineering\n",
    "2. Model Building\n",
    "3. Model Training\n",
    "4. Model Pickling\n",
    "5. API Creation\n",
    "6. Cloud Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da47a74f-1c71-4bf9-88a1-833c22b6f6d2",
   "metadata": {},
   "source": [
    "Q7. What is model deployment and why is it important?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952ad490-b288-4b93-b3c5-7d9b8a3bad5e",
   "metadata": {},
   "source": [
    "We have already learned that a dataset is divided into 3 parts train, validation and test. The train and validation data set is used for training the model while test dataset is used for testing the model. First the dataset is divided into train and test. Then the training dataset is divided into train and validation dataset. This separation is done with the help of train_test_split module of sklearn library. While splitting the dataset we give a value called test_size and random_state. The test_size determines the size of test dataset and random_state is used to determine size of validation dataset.\n",
    "But there is a catch. For different values of random_state we get different accuracy for the same training data. For example if random_state is 100 we might get accuracy of 85% or if random_state is 42 accuracy might be 70%. So to overcome this situation cross validation is used. \n",
    "Cross validation takes out the mean of all accuracy obtain by changing the random_state. For example if the random_state is changed thrice and the accuracy in these cases are 80%, 85% and 78% then the final accuracy after cross validation will be, (80+85+78)/3=81%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fe9ea0-a0d1-4518-9e04-08e556274904",
   "metadata": {},
   "source": [
    "Q8. Explain how multi-cloud platforms are used for model deployment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465fcbef-2565-4f63-8387-c92c0654ba3a",
   "metadata": {},
   "source": [
    "We have already learned that a dataset is divided into 3 parts train, validation and test. The train and validation data set is used for training the model while test dataset is used for testing the model. First the dataset is divided into train and test. Then the training dataset is divided into train and validation dataset. This separation is done with the help of train_test_split module of sklearn library. While splitting the dataset we give a value called test_size and random_state. The test_size determines the size of test dataset and random_state is used to determine size of validation dataset.\n",
    "But there is a catch. For different values of random_state we get different accuracy for the same training data. For example if random_state is 100 we might get accuracy of 85% or if random_state is 42 accuracy might be 70%. So to overcome this situation cross validation is used. \n",
    "Cross validation takes out the mean of all accuracy obtain by changing the random_state. For example if the random_state is changed thrice and the accuracy in these cases are 80%, 85% and 78% then the final accuracy after cross validation will be, (80+85+78)/3=81%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe34859-8142-4e68-82bf-8153a1e96f9a",
   "metadata": {},
   "source": [
    "Q9. Discuss the benefits and challenges of deploying machine learning models in a multi-cloud\n",
    "environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f22bf1-3f3c-4ac2-8a07-5b829b5372fe",
   "metadata": {},
   "source": [
    "We have already learned that a dataset is divided into 3 parts train, validation and test. The train and validation data set is used for training the model while test dataset is used for testing the model. First the dataset is divided into train and test. Then the training dataset is divided into train and validation dataset. This separation is done with the help of train_test_split module of sklearn library. While splitting the dataset we give a value called test_size and random_state. The test_size determines the size of test dataset and random_state is used to determine size of validation dataset.\n",
    "But there is a catch. For different values of random_state we get different accuracy for the same training data. For example if random_state is 100 we might get accuracy of 85% or if random_state is 42 accuracy might be 70%. So to overcome this situation cross validation is used. \n",
    "Cross validation takes out the mean of all accuracy obtain by changing the random_state. For example if the random_state is changed thrice and the accuracy in these cases are 80%, 85% and 78% then the final accuracy after cross validation will be, (80+85+78)/3=81%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0061c4b2-f67e-4768-b42e-d29c211a9b90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
