{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd803c8e-1d1d-476f-af85-62454ef59f7f",
   "metadata": {},
   "source": [
    "Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd98def-b98c-4ac9-a1d3-7f98137e768f",
   "metadata": {},
   "source": [
    "Given class variable y and dependent feature vector x_1 through x_n, Bayes Theorem states:\n",
    "P(y│x_1,x_2,……x_n )=(P(y)×P(x_1,x_2,……x_n│y))/(P(x_1,x_2,……x_n))\n",
    "Here,\n",
    "y & x_1,x_2,……x_n are the events (i.e.y=A & x_1,x_2,……x_n=B) \n",
    "P(y│x_1,x_2,……x_n ) is the probability of y given (x_1,x_2,……x_n) is true\n",
    "P⁡(x_1,x_2,……x_n |y) is the probability of (x_1,x_2,……x_n) given y is true\n",
    "P⁡(y),P⁡(x_1,x_2,……x_n ) are the independent probability of y and x_1,x_2,……x_n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c7ae18-d1f5-49f0-a5cf-4e3cf4209199",
   "metadata": {},
   "source": [
    "Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a677eb6-9f1b-4b55-be83-faf26b0d40b1",
   "metadata": {},
   "source": [
    "P(y│x_1,x_2,……x_n )=(P(y)×P(x_1,x_2,……x_n│y))/(P(x_1,x_2,……x_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e19586-9a33-4ae6-a3a3-6b2e8196b125",
   "metadata": {},
   "source": [
    "Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bda8feb-e145-4cd5-8c55-125d4c70218b",
   "metadata": {},
   "source": [
    "Let us understand this with help of an example, we have a dataset with 3 features – x_1,x_2  & x_3. The output feature is a binary classification with values Yes & No. We will be using the Naïve Bayes classifier to predict the output. In this case we will let the given output feature as variable y (i.e. variable of naïve bayes) and x_1,x_2  & x_3 as vectors. We have to predict P(y|x_1,x_2,x_3).\n",
    "Using Naïve Bayes we get:\n",
    "P(y│x_1,x_2,x_3 )=(P(y)×P(x_1,x_2,x_3 |y))/(P(x_1,x_2,x_3))\n",
    "On expanding we get:\n",
    "P(y│x_1,x_2,x_3 )=(P(y)×P(x_1 |y)×P(x_2 |y)×P(x_3 |y))/(P(x_1)×P(x_2)×P(x_3))\n",
    "Using this equation we will make predictions of each category of the output feature which is yes & no, as output is a binary classification. So we will let the variable y as yes and no respectively.\n",
    "For y=yes,  \n",
    "P(yes│x_1,x_2,x_3 )=(P(yes)×P(x_1 |yes)×P(x_2 |yes)×P(x_3 |yes))/(P(x_1)×P(x_2)×P(x_3))\n",
    "For y=no,\n",
    "P(no│x_1,x_2,x_3 )=(P(no)×P(x_1 |no)×P(x_2 |no)×P(x_3 |no))/(P(x_1)×P(x_2)×P(x_3))\n",
    "Now based on the values of x_1,x_2  & x_3 the category (yes & no) which has higher probability will be the prediction of output for new data of x_1,x_2  & x_3. \n",
    "Say for x_1=5,x_2=7 & x_3=12\n",
    "P(yes│x_1,x_2,x_3 )=0.67 \n",
    "And P(no│x_1,x_2,x_3 )=0.33. \n",
    "Then prediction for new data of  x_1=5,x_2=7 & x_3=12 will be \"yes\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6686ca4-103c-404d-bd05-e048cc64f8c2",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fa9766-91a7-4ea5-a6f9-9618d901af0f",
   "metadata": {},
   "source": [
    "Let us understand this with help of an example, we have a dataset with 3 features – x_1,x_2  & x_3. The output feature is a binary classification with values Yes & No. We will be using the Naïve Bayes classifier to predict the output. In this case we will let the given output feature as variable y (i.e. variable of naïve bayes) and x_1,x_2  & x_3 as vectors. We have to predict P(y|x_1,x_2,x_3).\n",
    "Using Naïve Bayes we get:\n",
    "P(y│x_1,x_2,x_3 )=(P(y)×P(x_1,x_2,x_3 |y))/(P(x_1,x_2,x_3))\n",
    "On expanding we get:\n",
    "P(y│x_1,x_2,x_3 )=(P(y)×P(x_1 |y)×P(x_2 |y)×P(x_3 |y))/(P(x_1)×P(x_2)×P(x_3))\n",
    "Using this equation we will make predictions of each category of the output feature which is yes & no, as output is a binary classification. So we will let the variable y as yes and no respectively.\n",
    "For y=yes,  \n",
    "P(yes│x_1,x_2,x_3 )=(P(yes)×P(x_1 |yes)×P(x_2 |yes)×P(x_3 |yes))/(P(x_1)×P(x_2)×P(x_3))\n",
    "For y=no,\n",
    "P(no│x_1,x_2,x_3 )=(P(no)×P(x_1 |no)×P(x_2 |no)×P(x_3 |no))/(P(x_1)×P(x_2)×P(x_3))\n",
    "Now based on the values of x_1,x_2  & x_3 the category (yes & no) which has higher probability will be the prediction of output for new data of x_1,x_2  & x_3. \n",
    "Say for x_1=5,x_2=7 & x_3=12\n",
    "P(yes│x_1,x_2,x_3 )=0.67 \n",
    "And P(no│x_1,x_2,x_3 )=0.33. \n",
    "Then prediction for new data of  x_1=5,x_2=7 & x_3=12 will be \"yes\"\n",
    "This is the Naïve Bayes Machine Learning Algorithm and its maths intuition\n",
    "V\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6096e8-170e-447a-9f2a-aace6135eb9a",
   "metadata": {},
   "source": [
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9d5723-a5a3-41b3-b5b2-10a5830665a8",
   "metadata": {},
   "source": [
    "There are 3 major variants of Naïve Bayes.\n",
    "i.\tBernoulli Naïve Bayes: Bernoulli Naïve Bayes is used whenever the features of the dataset are following the Bernoulli distribution.\n",
    "ii.\tMultinomial Naïve Bayes: Multinomial Naïve Bayes is used when the input data is in form of text message, document, paragraph or simply text. The text is converted into numerical values using Natural Language Processing in order to build model. \n",
    "iii.\tGaussian Naïve Bayes: If the features are following Gaussian distribution then we will use Gaussian Naïve Bayes Algorithm to solve the classification problem. This variant of Naïve Bayes is useful when input features are continuous values like age, height, weight etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a83c6a-e00b-4ea1-9f6b-c628ac72748c",
   "metadata": {},
   "source": [
    "Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A 3 3 4 4 3 3 3\n",
    "B 2 2 1 2 2 2 3\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96208b00-d932-4458-938f-9f17f8b8de24",
   "metadata": {},
   "source": [
    "Class A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1450d1b3-360b-41f1-b81f-98289a68bda9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d4d4520-0ab7-4e28-a28a-c7a476d55e2f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
