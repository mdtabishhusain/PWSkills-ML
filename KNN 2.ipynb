{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41eae4d6-cf08-4f12-a1a3-3c70593be9ae",
   "metadata": {},
   "source": [
    "Q1. What is the main difference between the Euclidean distance metric and the Manhattan distance\n",
    "metric in KNN? How might this difference affect the performance of a KNN classifier or regressor?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a312c0-2d96-45fa-bc73-1fd1e4867c4f",
   "metadata": {},
   "source": [
    "Euclidian Distance: For 2d data points with coordinates (x_1,y_1) for first data point and (x_2,y_2) for the other. Euclidian distance formula will be:\n",
    "Distance=√((x_2-x_1 )^2+(y_2-y_1 )^2 )\n",
    "For 3d data points with coordinates (x_1,y_1,z_1) for first data point and (x_2,y_2,z_2) for the second data point. The Euclidian Distance formula will be:\n",
    "Distance=√((x_2-x_1 )^2+(y_2-y_1 )^2+(z_2-z_1 )^2 )\n",
    "The Euclidian distance metric uses Pythagoras theorem for calculating the distance.\n",
    "Manhattan Distance: This distance is also known as taxicab distance or city block distance that is because the way this distance is calculated. The distance between two points is the sum of the absolute differences of their Cartesian coordinates. Manhattan distance is calculated by formula:\n",
    "D(x,y)=∑_(i=1)^n▒|x_i-y_i | \n",
    "We use both the distance metrics simultaneously and the one which gives higher accuracy is preferred.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509e6641-0c6d-4974-bd5b-703b74ba9122",
   "metadata": {},
   "source": [
    "Q2. How do you choose the optimal value of k for a KNN classifier or regressor? What techniques can be\n",
    "used to determine the optimal k value?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bf5611-d6fa-43fc-a97a-7ba292d39cd5",
   "metadata": {},
   "source": [
    "There is a problem in KNN algorithm. As there could be hundreds or thousands or sometimes even millions of data points in the data set. Whenever there is a new data point then its distance is calculated from all the data points and then using the K value the top nearest points are identified, this technique is known as brute search. So time complexity becomes very high. Therefore we use variants of KNN to overcome this problem\n",
    "Generally we use 2 variants:\n",
    "\tK Dimension (KD) tree\n",
    "\tBall tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1ee921-6db5-4913-a740-c866749256f6",
   "metadata": {},
   "source": [
    "Q3. How does the choice of distance metric affect the performance of a KNN classifier or regressor? In\n",
    "what situations might you choose one distance metric over the other?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e44f2d-2c37-43f8-bf32-331e1d5371d8",
   "metadata": {},
   "source": [
    "The K-Nearest Neighbor (KNN) algorithm is a popular machine learning technique used for classification and regression tasks. It relies on the idea that similar data points tend to have similar labels or values.\n",
    "During the training phase, the KNN algorithm stores the entire training dataset as a reference. When making predictions, it calculates the distance between the input data point and all the training examples, using a chosen distance metric such as Euclidean distance.\n",
    "Next, the algorithm identifies the K nearest neighbors to the input data point based on their distances. In the case of classification, the algorithm assigns the most common class label among the K neighbors as the predicted label for the input data point. For regression, it calculates the average or weighted average of the target values of the K neighbors to predict the value for the input data point.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559d8199-40d5-4d1a-a453-c47309a0c8de",
   "metadata": {},
   "source": [
    "Q4. What are some common hyperparameters in KNN classifiers and regressors, and how do they affect\n",
    "the performance of the model? How might you go about tuning these hyperparameters to improve\n",
    "model performance?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4c7f6d-5be5-47d0-b5ee-b76e13efe005",
   "metadata": {},
   "source": [
    "There is a problem in KNN algorithm. As there could be hundreds or thousands or sometimes even millions of data points in the data set. Whenever there is a new data point then its distance is calculated from all the data points and then using the K value the top nearest points are identified, this technique is known as brute search. So time complexity becomes very high. Therefore we use variants of KNN to overcome this problem\n",
    "Generally we use 2 variants:\n",
    "\tK Dimension (KD) tree\n",
    "\tBall tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8364e3c7-7dca-44f1-85d2-028592d628ee",
   "metadata": {},
   "source": [
    "Q5. How does the size of the training set affect the performance of a KNN classifier or regressor? What\n",
    "techniques can be used to optimize the size of the training set?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2635fecd-4175-4282-bcd7-474431a390ed",
   "metadata": {},
   "source": [
    "There is a problem in KNN algorithm. As there could be hundreds or thousands or sometimes even millions of data points in the data set. Whenever there is a new data point then its distance is calculated from all the data points and then using the K value the top nearest points are identified, this technique is known as brute search. So time complexity becomes very high. Therefore we use variants of KNN to overcome this problem\n",
    "Generally we use 2 variants:\n",
    "\tK Dimension (KD) tree\n",
    "\tBall tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487aa663-29ac-4ddd-9cee-b3c4ff429863",
   "metadata": {},
   "source": [
    "Q6. What are some potential drawbacks of using KNN as a classifier or regressor? How might you\n",
    "overcome these drawbacks to improve the performance of the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b652dd88-1c5d-40dc-82fd-ea8172788455",
   "metadata": {},
   "source": [
    "There is a problem in KNN algorithm. As there could be hundreds or thousands or sometimes even millions of data points in the data set. Whenever there is a new data point then its distance is calculated from all the data points and then using the K value the top nearest points are identified, this technique is known as brute search. So time complexity becomes very high. Therefore we use variants of KNN to overcome this problem\n",
    "Generally we use 2 variants:\n",
    "\tK Dimension (KD) tree\n",
    "\tBall tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5277e8-b85b-405a-a21d-98aee8ad520e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
