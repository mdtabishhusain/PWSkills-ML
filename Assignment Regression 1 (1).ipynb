{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5d27a9e-7a4b-4e72-b4e4-c70223a448e3",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7b6476-c50f-4b7a-8e1c-39131d65fa49",
   "metadata": {},
   "source": [
    "simple linear regression when we have a single input variable and an output variable. So a 2D graph is formed. But when we have multiple input variables, we use multiple linear regression and the graph formed is a 3D one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9161aa6f-3465-4354-8e5e-2a18a1555db8",
   "metadata": {},
   "source": [
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ef2876-fc2b-4b2c-9ba8-6ba9979355fe",
   "metadata": {},
   "source": [
    "Linear regression is used to solve regression problems of continuous variables. Let’s understand linear regression by solving a problem using linear regression.\n",
    "We have a dataset containing 2 variables weight and height. This is a train dataset. We have to train a model using this dataset and create a hypothesis. The work of hypothesis is to predict the height using new weight data i.e. weight is the input and height is the output. The output variable (height) is a continuous variable that means it can be any value. Let’s plot the points on a graph of weight (x – axis) and height (y – axis) according to the training dataset of weight and height.\n",
    "The working of linear regression is very simple. It will create a straight line through the data points shown in the graph. This line is known as bets fit line. The best fit line creates a model or hypothesis which will help in predicting height according to new weight values in the future.\n",
    "For example, look at the graph, the green point on the x – axis is new value of weight. So the best fit line helps in predicting what will be the height according to new weight value.\n",
    "Let’s understand most important thing for training point of view; we have plotted these points according to weight and height given in the training dataset. The cross point in white on the graph are the actual values. When we create the best fit line (i.e. straight line), the predicted values shown in green on the graph lies on the best fit line.\n",
    "The distance between an actual point and a predicted point is called residual error. Our main aim is to create a best fit line where the sum of all residual error is minimum. There might be multiple lines but the best fit line will be the one with minimum sum of all residual errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2789c43b-f093-44c5-b639-829a03efbcd3",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad024f7-196f-4fc2-85d5-ddbb1eb58dcd",
   "metadata": {},
   "source": [
    "Slope: Slope is the most important thing to change. It signifies 1 unit increase in x leads to how many units increase in y. The increased value of x & y are denoted by ∆x & ∆y respectively. Slope is shown on the graph here. To find slope we use: \n",
    " \t\t\t\tm=∆x/∆y\n",
    "Intercept: When the value of x is 0 the point where the best fit line intercept y is c or intercept as we can observe it on the graph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e36bdc-37dc-4869-9ec8-f9c6c89f87fe",
   "metadata": {},
   "source": [
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a68e22-cf3b-4095-a4f3-19ad972771c5",
   "metadata": {},
   "source": [
    "To understand gradient curve first look at the example below:\n",
    "h_θ (x)=θ_0+θ_1 x_1 \n",
    "Let’s θ_0=0\n",
    "h_θ (x)=θ_1 x_1 \n",
    "We have to understand how we will change θ_1 to get best fit line and also what is the relationship between hypothesis testing and cost function\n",
    "Consider we have 3 data points (1), (2), (3) of variable x \n",
    "If θ_1=1\n",
    "h_θ (x)=1×1 For x_1=1\n",
    "h_θ (x)=1×2 For x_1=2\n",
    "h_θ (x)=1×3 For x_1=3\n",
    "We will plot these points on graph and draw a best fit line i.e. the one shown in red colour in the graph.\n",
    "Also the line will pass through intercept because θ_0=0\n",
    "We will calculate cost function based on this best fit line.\n",
    "θ_1=1 \n",
    "J(θ_1 )=1/3[(1-1)^2+(2-2)^2+(3-3)^2]\n",
    "J(θ_1 )=0 \n",
    "We will plot this as first point on cost function graph.\n",
    "Now we will assume other values for θ_1\n",
    "If θ_1=0.5\n",
    "h_θ (x)=0.5×1 For x_1=0.5\n",
    "h_θ (x)=0.5×2 For x_1=1\n",
    "〖h〗_θ (x)=0.5×3 For x_1=1.5\n",
    "We will plot these points on graph and draw another best fit line i.e. the one shown in blue colour in the graph.\n",
    "Now we will calculate cost function based on second best fit line. \n",
    "θ_1=0.5 \n",
    "J(θ_1 )=1/3[(1-0.5)^2+(2-0.5)^2+(3-0.5)^2]\n",
    "J(θ_1 )=1/3  3.5\n",
    "J(θ_1 )≈1.16\n",
    "Now let θ_1=0.0\n",
    "h_θ (x)=0.0×1 For x_1=0\n",
    "h_θ (x)=0.0×2 For x_1=0\n",
    "h_θ (x)=0.0×3 For x_1=0\n",
    "We will plot these points on graph and draw another best fit line i.e. the one shown in yellow colour in the graph.\n",
    "Now we will calculate cost function based on third best fit line. \n",
    "θ_1=0.0\n",
    "J(θ_1 )=1/3[(1-0)^2+(2-0)^2+(3-0)^2]\n",
    "J(θ_1 )=14/3  \n",
    "J(θ_1 )≈4.66\n",
    "If we keep taking different values of θ_1 we will observe points are forming a curve on the cost function graph. If we combine all the points in the graph into a curve, the curve is known as gradient descent or optimizer. Gradient Descent automatically changes the value of θ_1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d3d76c-5b39-4983-a446-7e2d5b3ba12a",
   "metadata": {},
   "source": [
    "\n",
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0955ca-871f-4dc0-a913-d07706bd07c9",
   "metadata": {},
   "source": [
    "Till now we have learn about simple linear regression when we have a single input variable and an output variable. So a 2D graph is formed. But when we have multiple input variables, we use multiple linear regression and the graph formed is a 3D one.\n",
    "For example in a dataset of house pricing, there are 2 input variables namely x_1& x_2 and an output variable y. In this scenario, instead of finding a best fit line, we will find a 2D plane and with help of this plane we will project data points and find the prediction. So here we will use multiple linear regression.\n",
    "The 2D plane formed in this case is denoted by h_θ (x) and is given by\n",
    "h_θ (x)=θ_0+θ_1 x_1+θ_2 x_2\n",
    "Where,\n",
    "θ_0 is intercept\n",
    "θ_1  & θ_2 are the slopes\n",
    "x_1  & x_2 are the data points  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc390e7c-a019-4433-a3b8-e0f40403e0f3",
   "metadata": {},
   "source": [
    "\n",
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9397c267-d2de-4609-bb7f-63f28c38f0be",
   "metadata": {},
   "source": [
    "Generic equation for multiple linear regression for n input variables is given by:\n",
    "h_θ (x)=θ_0+θ_1 x_1+θ_2 x_2+θ_3 x_3……θ_n x_n\n",
    "Besides generic equation the gradient descent graph of multiple linear regression will also have a visual dissimilarity with simple regression as seen in the graph below. This dissimilarity is only visual, mathematical intuition will be similar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de5e4c6-643d-4079-b0ac-8740459d6722",
   "metadata": {},
   "source": [
    "\n",
    "Q7. Describe the polynomial regression model. How is it different from linear regression?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385756ac-da16-47fe-b143-11fcf184dcb5",
   "metadata": {},
   "source": [
    "When there is a non-linear relationship between the data points of the input variables and it is not befitting to draw a best fit line we use a curve instead of best fit line. This is known as polynomial regression. Polynomial regression is further divided into 2 parts:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d65f6bb-711e-436d-927e-691fd9a00018",
   "metadata": {},
   "source": [
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccd56bb-c260-42c1-92e5-7032e20eccf7",
   "metadata": {},
   "source": [
    "Simple polynomial regression for polynomial degree = n is given by\n",
    "h_θ (x)=θ_0 x_1^0+θ_1 x_1^1+θ_2 x_1^2……+θ_n x_1^n\n",
    "As we kept increasing the degree we get a more fitted curve as shown in the second graph above. The rest of the mathematical intuition is similar to linear regression.\n",
    "MULTIPLE POLYNOMIAL REGRESSION\n",
    "Multiple polynomial regression if multiple linear regression is given as h_θ (x)=θ_0+θ_1 x_1+θ_2 x_2+θ_3 x_3  for polynomial degree = 2, is given as:\n",
    "h_θ (x)=θ_0+θ_1 x_1+θ_2 x_2+θ_3 x_3+θ_4 x_1^2+θ_5 x_2^2+θ_6 x_3^2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6172bd17-2fac-40d2-8bd6-2d2c47e3dcd8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
